{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-11-17 20:42:15--  https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv\n",
      "Resolving gist.githubusercontent.com (gist.githubusercontent.com)... 151.101.120.133\n",
      "Connecting to gist.githubusercontent.com (gist.githubusercontent.com)|151.101.120.133|:443... connected.\n",
      "WARNING: cannot verify gist.githubusercontent.com's certificate, issued by ‘CN=DigiCert SHA2 High Assurance Server CA,OU=www.digicert.com,O=DigiCert Inc,C=US’:\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3858 (3.8K) [text/plain]\n",
      "Saving to: ‘iris.csv.3’\n",
      "\n",
      "iris.csv.3          100%[===================>]   3.77K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-11-17 20:42:15 (20.1 MB/s) - ‘iris.csv.3’ saved [3858/3858]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip -q install pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch as th\n",
    "from pytorch_lightning import LightningModule, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, path_to_csv: str) -> None:\n",
    "        rows = [] \n",
    "  \n",
    "        # reading csv file \n",
    "        with open(path_to_csv, 'r') as csvfile: \n",
    "            # creating a csv reader object \n",
    "            csvreader = csv.reader(csvfile) \n",
    "\n",
    "            # extracting field names through first row \n",
    "            fields = next(csvreader) \n",
    "\n",
    "            # extracting each data row one by one \n",
    "            for row in csvreader: \n",
    "                rows.append(row)\n",
    "                \n",
    "        # TODO 1\n",
    "        # Encode the species into a numerical values (we need to reason with numbers, not strings)\n",
    "        # Split it into 2 lists, the data and the labels\n",
    "        # Convert of of the 2 lists into 2 lists of tensors to be used with our model\n",
    "        \n",
    "        self.data = None\n",
    "        self.labels = None\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        # TODO 2\n",
    "        # return the total length of the dataset\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> tuple:\n",
    "        # TODO 3\n",
    "        # return the data at index idx and the label\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = IrisDataset(\"./iris.csv\")\n",
    "\n",
    "# split the data that you have into train and test\n",
    "train_size = int(0.8 * len(data))\n",
    "test_size = len(data) - train_size\n",
    "\n",
    "train_dataset, test_dataset = th.utils.data.random_split(data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-6-809ab6fee0c9>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-809ab6fee0c9>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=1, workers)\u001b[0m\n\u001b[0m                                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# TODO 4\n",
    "# Create the train dataloader with shuffling, a batch size of 5 and 2 workers. Use the docs!\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=1, workers=2)\n",
    "\n",
    "# TODO 5\n",
    "# Create the test dataloader with no shuffling, a batch size of 5 and 2 workers. Use the docs!\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=1, workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisModel(LightningModule):\n",
    "    def __init__(self, input_dim=4, output_dim=1):\n",
    "        super(IrisModel, self).__init__()\n",
    "        \n",
    "        # TODO 6\n",
    "        # Define your fully connected arhitecture here\n",
    "        # With 2 layers and 1 non-linearity (sigmoid)\n",
    "        \n",
    "        # Hints: \n",
    "        # What is the input size? \n",
    "        # What is the hidden size?\n",
    "        # What is the output size?\n",
    "        self.lin1 = None\n",
    "        self.sigmoid = None\n",
    "        self.lin2 = None\n",
    "        \n",
    "        # TODO 7: Pick a learning rate!\n",
    "        self.lr = None\n",
    "\n",
    "        # TODO 8: pick the L1 loss function for your model.\n",
    "        self.loss_function =  None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO 10: write the forward function\n",
    "        pass\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # TODO 11: pick your optimizer.\n",
    "        # Remeber to add the parameters to the optimizer!\n",
    "        # Don't forget the learning rate!\n",
    "        optimizer = None\n",
    "        return optimizer\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return train_dataloader\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return test_dataloader\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # TODO 12: write the training step on each batch.\n",
    "        # Remember, PyTorch Lightning will call loss.backward() for you!\n",
    "        # You only need to compute it for him.\n",
    "        loss = None\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # TODO 13: compute the same loss as above on the test set\n",
    "        loss = None\n",
    "        return {'val_loss': loss}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        train_loss_mean = sum([o[\"loss\"] for o in outputs]) / len(outputs)\n",
    "        self.log(\"train_loss_mean\", train_loss_mean)\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        val_loss_mean = sum([o['val_loss'] for o in outputs]) / len(outputs)\n",
    "        self.log(\"val_loss_mean\", val_loss_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IrisModel()\n",
    "\n",
    "trainer = Trainer(\n",
    "    # TODO 14: pick the number of epochs\n",
    "    max_epochs=None,\n",
    "    min_epochs=1,\n",
    "    auto_lr_find=False,\n",
    "    auto_scale_batch_size=False,\n",
    "    progress_bar_refresh_rate=0\n",
    ")\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 13: Inspect the tensorboard to see if it converges!\n",
    "# TODO BONUS: Compute the accuracy of the model (round the output) on the test set.\n",
    "# Achieve the best accuracy in the room!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
